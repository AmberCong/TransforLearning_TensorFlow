{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取及预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, init\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn \n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),])\n",
    "#     gdata.vision.transforms.Normalize([0.4914, 0.4822, 0.4465], \n",
    "#                                       [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "train_ds = gdata.vision.ImageFolderDataset(root = r'.\\images',\n",
    "                                           flag=1)  # 0转换为灰度图，1转换为彩色图\n",
    "\n",
    "loader = gluon.data.DataLoader  # 可迭代对象class，非迭代器class\n",
    "\n",
    "train_data = loader(dataset = train_ds.transform_first(transform_train), \n",
    "                    batch_size = 128,\n",
    "                    shuffle=True,\n",
    "                    last_batch='keep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络定义及初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    " \n",
    "class Residual(nn.HybridBlock):\n",
    "    def __init__(self, channels, same_shape=True, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.same_shape = same_shape\n",
    "        with self.name_scope():\n",
    "            strides = 1 if same_shape else 2\n",
    "            self.conv1 = nn.Conv2D(channels, kernel_size=3, padding=1,\n",
    "                                  strides=strides)\n",
    "            self.bn1 = nn.BatchNorm()\n",
    "            self.conv2 = nn.Conv2D(channels, kernel_size=3, padding=1)\n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            if not same_shape:\n",
    "                self.conv3 = nn.Conv2D(channels, kernel_size=1,\n",
    "                                       strides=strides)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        \"\"\"\n",
    "        conv(3*3 kernel, unknow stride)->bn->relu->conv(3*3 kernel, 1*1 stride)-bn\n",
    "        conv(1*1 kernal, unknow stride)\n",
    "        \"\"\"\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if not self.same_shape:\n",
    "            x = self.conv3(x)\n",
    "        return F.relu(out + x)\n",
    " \n",
    " \n",
    "class ResNet(nn.HybridBlock):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            net = self.net = nn.HybridSequential()\n",
    "            # 模块1\n",
    "            net.add(nn.Conv2D(channels=32, kernel_size=3, strides=1, padding=1))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            # 模块2\n",
    "            for _ in range(3):\n",
    "                net.add(Residual(channels=32))\n",
    "            # 模块3\n",
    "            net.add(Residual(channels=64, same_shape=False))\n",
    "            for _ in range(2):\n",
    "                net.add(Residual(channels=64))\n",
    "            # 模块4\n",
    "            net.add(Residual(channels=128, same_shape=False))\n",
    "            for _ in range(2):\n",
    "                net.add(Residual(channels=128))\n",
    "            # 模块5\n",
    "            net.add(nn.AvgPool2D(pool_size=8))\n",
    "            net.add(nn.Flatten())\n",
    "            net.add(nn.Dense(num_classes))\n",
    " \n",
    "    def hybrid_forward(self, F, x):\n",
    "        out = x\n",
    "        for i, b in enumerate(self.net):\n",
    "            out = b(out)\n",
    "            if self.verbose:\n",
    "                print('Block %d output: %s'%(i+1, out.shape))\n",
    "        return out\n",
    " \n",
    " \n",
    "def get_net(ctx):\n",
    "    num_outputs = 5\n",
    "    net = ResNet(num_outputs)\n",
    "    net.initialize(ctx=ctx, init=mx.init.Xavier())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预训练网络获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models\n",
    "\n",
    "pretrained_net = models.resnet18_v2(pretrained=True)\n",
    "finetune_net = models.resnet18_v2(classes=5)\n",
    "finetune_net.features = pretrained_net.features\n",
    "pretrained_net.features.collect_params().setattr('grad_req', 'null')  # 固定特征层参数\n",
    "finetune_net.output.initialize(init.Xavier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import gluonbook as gb\n",
    " \n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period, lr_decay):\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        if epoch > 0 and epoch % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            label = label.astype('float32').as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data.as_in_context(ctx))\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            train_acc += gb.accuracy(output, label)\n",
    "            # print(gb.accuracy(output, label))\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_acc = gb.evaluate_accuracy(valid_data, net, ctx)\n",
    "            epoch_str = (\"Epoch %d. Loss: %f, Train acc %f, Valid acc %f, \"\n",
    "                         % (epoch, train_loss / len(train_data),\n",
    "                            train_acc / len(train_data), valid_acc))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Loss: %f, Train acc %f, \"\n",
    "                         % (epoch, train_loss / len(train_data),\n",
    "                            train_acc / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        # net.export('./model/astro')\n",
    "        net.save_parameters('./model/astro_{}'.format(epoch))\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7734375\n",
      "0.6796875\n",
      "0.734375\n",
      "0.7265625\n",
      "0.734375\n",
      "0.6875\n",
      "0.796875\n",
      "0.7578125\n",
      "0.7734375\n",
      "0.7734375\n",
      "0.765625\n",
      "0.7578125\n",
      "0.7734375\n",
      "0.765625\n",
      "0.78125\n",
      "0.828125\n",
      "0.8203125\n",
      "0.7578125\n",
      "0.78125\n",
      "0.7734375\n",
      "0.8203125\n",
      "0.8125\n",
      "0.71875\n",
      "0.8515625\n",
      "0.765625\n",
      "0.84375\n",
      "0.8359375\n",
      "0.7734375\n",
      "0.796875\n",
      "0.8515625\n",
      "0.8\n",
      "Epoch 0. Loss: 0.462500, Train acc 0.777823, Time 00:01:41, lr 0.01\n",
      "0.78125\n",
      "0.8046875\n",
      "0.734375\n",
      "0.796875\n",
      "0.8046875\n",
      "0.78125\n",
      "0.8125\n",
      "0.7734375\n",
      "0.859375\n",
      "0.7890625\n",
      "0.8125\n",
      "0.765625\n",
      "0.828125\n",
      "0.71875\n",
      "0.828125\n",
      "0.734375\n",
      "0.7109375\n",
      "0.8046875\n",
      "0.8671875\n",
      "0.8046875\n",
      "0.859375\n",
      "0.7890625\n",
      "0.8359375\n",
      "0.7421875\n",
      "0.8046875\n",
      "0.8125\n",
      "0.734375\n",
      "0.7421875\n",
      "0.84375\n",
      "0.8359375\n",
      "0.8\n",
      "Epoch 1. Loss: 0.438689, Train acc 0.793952, Time 00:01:47, lr 0.01\n",
      "0.78125\n",
      "0.84375\n",
      "0.828125\n",
      "0.84375\n",
      "0.8515625\n",
      "0.890625\n",
      "0.890625\n",
      "0.875\n",
      "0.8515625\n",
      "0.8359375\n",
      "0.859375\n",
      "0.8828125\n",
      "0.8515625\n",
      "0.8984375\n",
      "0.875\n",
      "0.8828125\n",
      "0.875\n",
      "0.8984375\n",
      "0.9375\n",
      "0.8828125\n",
      "0.8125\n",
      "0.84375\n",
      "0.828125\n",
      "0.828125\n",
      "0.8046875\n",
      "0.8203125\n",
      "0.8125\n",
      "0.8671875\n",
      "0.8125\n",
      "0.7421875\n",
      "0.7\n",
      "Epoch 2. Loss: 0.346429, Train acc 0.845413, Time 00:01:44, lr 0.01\n",
      "0.84375\n",
      "0.84375\n",
      "0.8046875\n",
      "0.84375\n",
      "0.8515625\n",
      "0.8828125\n",
      "0.765625\n",
      "0.8515625\n",
      "0.8359375\n",
      "0.8984375\n",
      "0.890625\n",
      "0.859375\n",
      "0.890625\n",
      "0.8671875\n",
      "0.9140625\n",
      "0.8828125\n",
      "0.875\n",
      "0.8359375\n",
      "0.8828125\n",
      "0.859375\n",
      "0.8515625\n",
      "0.890625\n",
      "0.9296875\n",
      "0.90625\n",
      "0.8671875\n",
      "0.890625\n",
      "0.7890625\n",
      "0.8046875\n",
      "0.859375\n",
      "0.875\n",
      "0.9\n",
      "Epoch 3. Loss: 0.322081, Train acc 0.862702, Time 00:01:51, lr 0.01\n",
      "0.84375\n",
      "0.9140625\n",
      "0.9296875\n",
      "0.921875\n",
      "0.9453125\n",
      "0.9140625\n",
      "0.9140625\n",
      "0.890625\n",
      "0.921875\n",
      "0.9296875\n",
      "0.9140625\n",
      "0.9140625\n",
      "0.890625\n",
      "0.9375\n",
      "0.9140625\n",
      "0.8828125\n",
      "0.953125\n",
      "0.8984375\n",
      "0.90625\n",
      "0.8828125\n",
      "0.890625\n",
      "0.921875\n",
      "0.875\n",
      "0.9375\n",
      "0.90625\n",
      "0.8671875\n",
      "0.90625\n",
      "0.84375\n",
      "0.9375\n",
      "0.8515625\n",
      "1.0\n",
      "Epoch 4. Loss: 0.228639, Train acc 0.908266, Time 00:01:48, lr 0.01\n"
     ]
    }
   ],
   "source": [
    "ctx = gb.try_gpu()\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01\n",
    "weight_decay = 5e-4\n",
    "lr_period = 80\n",
    "lr_decay = 0.1\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "finetune = False  # <-----是否使用yu'xun'lian\n",
    "if finetune:\n",
    "    finetune_net.collect_params().reset_ctx(ctx)\n",
    "    finetune_net.hybridize()\n",
    "    net = finetune_net\n",
    "else:\n",
    "    net = get_net(ctx)\n",
    "    net.hybridize()\n",
    "    net.load_parameters('./model/astro_0')\n",
    "\n",
    "train(net, train_data, None, num_epochs, learning_rate,\n",
    "      weight_decay, ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
